# Golden Dataset Generation Configuration

# Generation settings
generation:
  testset_size: 2  # Minimal size to debug sample generation
  output_directory: 'eval/fixtures'
  filename_prefix: 'golden_dataset'

# AI models for testset generation
models:
  generator_llm:
    model: 'gpt-4.1-nano'
    temperature: 0.7  # Some creativity for diverse questions
  critic_llm:
    model: 'gpt-4.1-mini'
    temperature: 0.1  # More consistent for evaluation
  embedding_model: 'text-embedding-3-small'

# Query distribution for different question types (must sum to 1.0)
query_distribution:
  single_hop_specific: 0.5    # Basic factual questions about ethics rules
  multi_hop_abstract: 0.3     # Complex ethical reasoning scenarios
  multi_hop_specific: 0.2     # Questions requiring multiple sources

# Default user context for generated scenarios
default_user_context:
  role: 'federal_employee'
  agency: 'Various'
  seniority: 'GS-12'

# Dataset metadata
metadata:
  dataset_name: 'Federal Ethics Golden Dataset'
  description: 'Synthetic test cases generated using RAGAS TestsetGenerator from federal ethics laws'
  version: '1.0'
  source: 'federal_ethics_laws'
