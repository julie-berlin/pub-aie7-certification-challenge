# FastAPI Backend Setup & Documentation

## âœ… Current Status

**COMPLETED**: Full FastAPI backend with parallel agentic workflow

### ğŸ—ï¸ Architecture

**Modular Service Design** (no global instances):
- `PlanningAgentService` - Research strategy with GPT-4o-mini
- `EthicsAssessmentService` - Comprehensive analysis with GPT-4o
- `DocumentLoaderService` - PDF loading with tiktoken chunking
- `VectorStoreService` - Qdrant vector database operations
- `WebSearchService` - Parallel Tavily web searches
- `AgenticWorkflowService` - LangGraph workflow orchestration

**Configuration Management**:
- YAML config files in `api/config/`
- Environment variable override support
- Path-aware configuration loading

**Parallel Agentic Workflow**:
```
collect_context â†’ create_plan â†’ retrieve_knowledge
                                        â†“
        ğŸ”¥ PARALLEL: search_general | search_penalties | search_guidance
                                        â†“
        combine_results â†’ assess_violation â†’ finalize
```

### ğŸ“ Project Structure

```
api/
â”œâ”€â”€ config/                   # YAML configuration files
â”‚   â”œâ”€â”€ agentic_workflow.yaml # Workflow parameters
â”‚   â”œâ”€â”€ ai_models.yaml        # LLM configuration
â”‚   â”œâ”€â”€ application.yaml      # API and security settings
â”‚   â”œâ”€â”€ data_processing.yaml  # Document processing
â”‚   â”œâ”€â”€ golden_dataset.yaml   # Test dataset settings
â”‚   â””â”€â”€ vector_database.yaml  # Qdrant settings
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config_loader.py  # YAML config loading
â”‚   â”‚   â””â”€â”€ settings.py       # Centralized settings
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ chat_models.py    # Pydantic request/response models
â”‚   â”‚   â””â”€â”€ state_models.py   # LangGraph state definitions
â”‚   â”œâ”€â”€ services/             # Business logic services
â”‚   â”‚   â”œâ”€â”€ advanced_retriever_service.py
â”‚   â”‚   â”œâ”€â”€ agentic_workflow_service.py
â”‚   â”‚   â”œâ”€â”€ document_loader_service.py
â”‚   â”‚   â”œâ”€â”€ document_upload_service.py
â”‚   â”‚   â”œâ”€â”€ ethics_assessment_service.py
â”‚   â”‚   â”œâ”€â”€ planning_agent_service.py
â”‚   â”‚   â”œâ”€â”€ startup_service.py
â”‚   â”‚   â”œâ”€â”€ vector_store_service.py
â”‚   â”‚   â””â”€â”€ web_search_service.py
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ chat_router.py    # API endpoints
|   |   â””â”€â”€ document_router.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ startup_utils.py  # Environment validation
â”‚   â””â”€â”€ main.py               # FastAPI application
â”œâ”€â”€ run_server.py             # Server startup script
â””â”€â”€ test_api.py               # API test suite
```

### ğŸ”Œ API Endpoints

**Main Endpoints**:
- `POST /api/chat` - Ethics consultation with full agentic workflow
- `POST /api/documents/upload` - Add user document
- `GET /api/documents/list` - Get list of uploaded documents
- `GET /api/documents/{id}` - Get uploaded document with {id}
- `DELETE /api/documents/{id}` - Delete a user added document with {id}
- `GET /api/health` - Service health check with component status
- `GET /api/ping` - Simple connectivity test

**Request Format**:
```json
{
  "question": "Ethics question or scenario",
  "user_context": {
    "role": "federal_employee",
    "agency": "GSA",
    "seniority": "GS-14",
    "clearance": "secret"
  },
}
```

**Response Format**:
```json
{
  "question": "Original question",
  "response": "Comprehensive ethics guidance",
  "federal_law_sources": 5,
  "web_sources": 9,
  "search_results": [...],
  "processing_time_seconds": 8.5,
  "search_plan": "Research strategy used"
}
```

### âš¡ Performance Features

**Parallel Web Search**: 3x speed improvement
- `search_general`: OGE guidance and general ethics
- `search_penalties`: Criminal, civil, administrative penalties
- `search_guidance`: Current guidance and precedent cases

**Multi-Model Approach**:
- GPT-4o-mini for planning (cost-effective, fast)
- GPT-4o for assessment (high quality)

**Smart Configuration**:
- Path-aware config loading (works from any directory)
- Environment variable overrides
- Validation and error handling

### ğŸš€ Setup Instructions

**1. Install Dependencies**:
```bash
uv sync
```

**2. Environment Variables** (create `.env.local`):
```bash
OPENAI_API_KEY=your_openai_key
TAVILY_API_KEY=your_tavily_key
LANGCHAIN_API_KEY=your_langsmith_key
```

**3. Start Server** (from project root):
```bash
python3 start_backend.py
```

**4. Test API**:
```bash
python3 api/test_api.py
```

**5. Access Documentation**:
- API Docs: http://localhost:8000/docs
- Health Check: http://localhost:8000/api/health

### ğŸ”§ Configuration

**Key Configuration Files**:
- `application.yaml` - API settings, CORS, environment
- `ai_models.yaml` - Model selection, parameters
- `vector_database.yaml` - Qdrant configuration
- `agentic_workflow.yaml` - Timeout settings, parallel config

**Environment Override Example**:
```bash
export OPENAI_MODEL="gpt-4o-mini"  # Override default model
export QDRANT_URL="http://production-qdrant:6333"
```
