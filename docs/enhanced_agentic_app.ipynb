{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce44fed",
   "metadata": {},
   "source": [
    "# Federal Ethics Compliance Chatbot - Enhanced Agentic Version\n",
    "\n",
    "This notebook demonstrates an enhanced agentic RAG system with planning agent and reflection steps for comprehensive federal ethics guidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5c74714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OPENAI_API_KEY configured\n",
      "✅ TAVILY_API_KEY configured\n",
      "✅ LANGCHAIN_API_KEY configured\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../.env.local')\n",
    "\n",
    "# Verify API keys are loaded\n",
    "required_keys = ['OPENAI_API_KEY', 'TAVILY_API_KEY', 'LANGCHAIN_API_KEY']\n",
    "for key in required_keys:\n",
    "    if not os.getenv(key):\n",
    "        print(f\"⚠️ Missing {key} in environment\")\n",
    "    else:\n",
    "        print(f\"✅ {key} configured\")\n",
    "\n",
    "# Set up LangSmith tracing\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"federal-ethics-chatbot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8176e847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.documents import Document\n",
    "from typing import List, Optional\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    response: str\n",
    "    user_context: Optional[dict]\n",
    "    search_plan: Optional[str]\n",
    "    violation_type: Optional[str]\n",
    "    web_results: List[dict]\n",
    "    assessment: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a126f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d12dc8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 Loaded 190 pages from federal ethics laws\n",
      "📄 First page preview: COMPILATION OF \n",
      "FEDERAL ETHICS LAWS \n",
      "  \n",
      " \n",
      "PREPARED BY THE \n",
      "UNITED STATES OFFICE OF GOVERNMENT ETHICS...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "directory_loader = DirectoryLoader(\"../data\", glob=\"**/*.pdf\", loader_cls=PyMuPDFLoader)\n",
    "\n",
    "ethics_knowledge_resources = directory_loader.load()\n",
    "\n",
    "print(f\"📚 Loaded {len(ethics_knowledge_resources)} pages from federal ethics laws\")\n",
    "print(f\"📄 First page preview: {ethics_knowledge_resources[0].page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e3b72ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def tiktoken_len(text):\n",
    "    tokens = tiktoken.encoding_for_model(\"gpt-4o\").encode(\n",
    "        text,\n",
    "    )\n",
    "    return len(tokens)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 750,\n",
    "    chunk_overlap = 0,\n",
    "    length_function = tiktoken_len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0337e6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Split 190 pages into 198 chunks\n",
      "📊 Average chunk size: 2073 characters\n"
     ]
    }
   ],
   "source": [
    "usa_ethics_law_chunks = text_splitter.split_documents(ethics_knowledge_resources)\n",
    "\n",
    "print(f\"🔄 Split {len(ethics_knowledge_resources)} pages into {len(usa_ethics_law_chunks)} chunks\")\n",
    "print(f\"📊 Average chunk size: {sum(len(chunk.page_content) for chunk in usa_ethics_law_chunks) // len(usa_ethics_law_chunks)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b7b6209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "embedding_dim = 1536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71375a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "client = QdrantClient(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc153596",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_collection(\n",
    "    collection_name=\"ethics_knowledge_index\",\n",
    "    vectors_config=VectorParams(size=embedding_dim, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"ethics_knowledge_index\",\n",
    "    embedding=embedding_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d7f59c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Added 198 chunks to ethics knowledge index\n"
     ]
    }
   ],
   "source": [
    "vector_store.add_documents(documents=usa_ethics_law_chunks)\n",
    "print(f\"✅ Added {len(usa_ethics_law_chunks)} chunks to ethics knowledge index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5028e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2z9b5ke8853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Agentic System with Planning\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "planning_model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "\n",
    "PLANNING_TEMPLATE = \"\"\"\n",
    "You are a federal ethics research planning agent. Analyze the user's question to develop a comprehensive search and analysis strategy.\n",
    "\n",
    "USER QUESTION: {question}\n",
    "USER CONTEXT: {user_context}\n",
    "\n",
    "Create a structured research plan that includes:\n",
    "1. **Key Ethics Areas**: What specific federal ethics laws/regulations to focus on\n",
    "2. **Search Terms**: Targeted web search terms for current guidance\n",
    "3. **Risk Factors**: Potential aggravating or mitigating circumstances\n",
    "4. **Analysis Focus**: What aspects need the deepest investigation\n",
    "\n",
    "Provide a concise but thorough research plan.\n",
    "\"\"\"\n",
    "\n",
    "planning_chain = ChatPromptTemplate.from_template(PLANNING_TEMPLATE) | planning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be398c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yr/gt3hr2h50zv15jd0htzpz2b40000gn/T/ipykernel_28779/4146332860.py:4: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  web_search_tool = TavilySearchResults(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Initialize web search tool\n",
    "web_search_tool = TavilySearchResults(\n",
    "    max_results=3,\n",
    "    search_depth=\"advanced\",\n",
    "    include_domains=[\"osg.gov\", \"oge.gov\", \"ethics.gov\", \"gsa.gov\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nvwxme9da6m",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_user_context(state: GraphState) -> GraphState:\n",
    "    \"\"\"Collect user context for personalized guidance\"\"\"\n",
    "    # In production, this would be a form input\n",
    "    # For demo, we'll extract from question or use defaults\n",
    "    default_context = {\n",
    "        \"role\": \"federal_employee\",\n",
    "        \"agency\": \"unknown\",\n",
    "        \"seniority\": \"mid_level\",\n",
    "        \"clearance\": \"unknown\"\n",
    "    }\n",
    "    return {\"user_context\": default_context}\n",
    "\n",
    "def create_search_plan(state: GraphState) -> GraphState:\n",
    "    \"\"\"Planning agent creates targeted research strategy\"\"\"\n",
    "    user_context_str = str(state.get(\"user_context\", {}))\n",
    "\n",
    "    plan_response = planning_chain.invoke({\n",
    "        \"question\": state[\"question\"],\n",
    "        \"user_context\": user_context_str\n",
    "    })\n",
    "\n",
    "    return {\"search_plan\": plan_response.content}\n",
    "\n",
    "def web_search(state: GraphState) -> GraphState:\n",
    "    \"\"\"Enhanced web search using planning agent's strategy\"\"\"\n",
    "    search_plan = state.get(\"search_plan\", \"\")\n",
    "\n",
    "    # Extract key terms from plan for targeted search\n",
    "    base_query = f\"federal ethics violation {state['question']}\"\n",
    "    if \"gift\" in state[\"question\"].lower():\n",
    "        query = f\"{base_query} penalties reporting requirements OGE guidance\"\n",
    "    elif \"conflict\" in state[\"question\"].lower():\n",
    "        query = f\"{base_query} recusal divestiture financial disclosure\"\n",
    "    elif \"employment\" in state[\"question\"].lower():\n",
    "        query = f\"{base_query} post-employment restrictions cooling off period\"\n",
    "    else:\n",
    "        query = f\"{base_query} penalties reporting requirements\"\n",
    "\n",
    "    try:\n",
    "        web_results = web_search_tool.invoke(query)\n",
    "        return {\"web_results\": web_results}\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Web search failed: {e}\")\n",
    "        return {\"web_results\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8xm2lj33of9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated functions for enhanced workflow\n",
    "def retrieve_ethics_knowledge(state: GraphState) -> GraphState:\n",
    "    \"\"\"Retrieve relevant federal ethics law documents with plan context\"\"\"\n",
    "    retrieved_docs = retriever.invoke(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def assess_ethics_violation(state: GraphState) -> GraphState:\n",
    "    \"\"\"Generate comprehensive ethics assessment with plan guidance\"\"\"\n",
    "    context_text = \"\\\\n\\\\n\".join([doc.page_content for doc in state[\"context\"]])\n",
    "    web_text = str(state.get(\"web_results\", []))\n",
    "    search_plan = state.get(\"search_plan\", \"\")\n",
    "    user_context = str(state.get(\"user_context\", {}))\n",
    "\n",
    "    # Enhanced prompt with plan and context\n",
    "    prompt = f\"\"\"\n",
    "    SEARCH PLAN: {search_plan}\n",
    "\n",
    "    USER CONTEXT: {user_context}\n",
    "\n",
    "    QUESTION: {state['question']}\n",
    "\n",
    "    FEDERAL ETHICS CONTEXT:\n",
    "    {context_text}\n",
    "\n",
    "    WEB SEARCH RESULTS:\n",
    "    {web_text}\n",
    "\n",
    "    Provide a comprehensive assessment following the search plan guidance:\n",
    "    1. **Violation Type**: What type of ethics violation this might be\n",
    "    2. **Severity Assessment**: Minor, moderate, or serious violation\n",
    "    3. **Legal Penalties**: Specific penalties from federal law\n",
    "    4. **Corrective Actions**: Immediate steps required\n",
    "    5. **Reporting Requirements**: Who to notify and deadlines\n",
    "    6. **Prevention**: How to avoid similar situations\n",
    "\n",
    "    Tailor the response to the user's role and context.\n",
    "    \"\"\"\n",
    "\n",
    "    response = planning_model.invoke(prompt)\n",
    "    return {\"response\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j0x2b6d3gpl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Enhanced Ethics Assessment Graph\n",
    "graph_builder = StateGraph(GraphState)\n",
    "\n",
    "# Add all nodes\n",
    "graph_builder.add_node(\"collect_context\", collect_user_context)\n",
    "graph_builder.add_node(\"create_plan\", create_search_plan)\n",
    "graph_builder.add_node(\"retrieve\", retrieve_ethics_knowledge)\n",
    "graph_builder.add_node(\"search_web\", web_search)\n",
    "graph_builder.add_node(\"assess\", assess_ethics_violation)\n",
    "\n",
    "# Define the enhanced flow with planning\n",
    "graph_builder.add_edge(START, \"collect_context\")\n",
    "graph_builder.add_edge(\"collect_context\", \"create_plan\")\n",
    "graph_builder.add_edge(\"create_plan\", \"retrieve\")\n",
    "graph_builder.add_edge(\"retrieve\", \"search_web\")\n",
    "graph_builder.add_edge(\"search_web\", \"assess\")\n",
    "\n",
    "# Compile the enhanced graph\n",
    "ethics_graph = graph_builder.compile()\n",
    "\n",
    "print(\"🧠 Enhanced Ethics Assessment Graph Compiled\")\n",
    "print(\"Flow: collect_context → create_plan → retrieve → search_web → assess\")\n",
    "print(\"✅ Planning agent integrated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331b3735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced System Summary\n",
    "print(\"📝 ENHANCED FEDERAL ETHICS CHATBOT - SYSTEM SUMMARY\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "print(\"\"\"\n",
    "🏗️ ENHANCED ARCHITECTURE:\n",
    "├── User Context Collection (role, agency, seniority)\n",
    "├── Planning Agent (research strategy with GPT-4o-mini)\n",
    "├── Data Layer: Federal Ethics Laws PDF (190 pages)\n",
    "├── Vector Store: Qdrant in-memory with OpenAI embeddings\n",
    "├── Enhanced Web Search: Tavily with plan-guided queries\n",
    "└── Assessment Engine: Comprehensive ethics analysis (GPT-4o)\n",
    "\n",
    "🤖 ENHANCED AGENTIC WORKFLOW:\n",
    "1. User Context Collection (role, agency, clearance level)\n",
    "2. Planning Agent (creates targeted research strategy)\n",
    "3. Knowledge Retrieval (federal law RAG with plan context)\n",
    "4. Enhanced Web Search (plan-guided search terms)\n",
    "5. Comprehensive Assessment (violation, severity, penalties)\n",
    "\n",
    "✅ CAPABILITIES:\n",
    "- Strategic research planning before execution\n",
    "- Context-aware guidance based on user role/agency\n",
    "- Enhanced search strategy with targeted terms\n",
    "- Multi-model approach (GPT-4o + GPT-4o-mini)\n",
    "- Identifies potential federal ethics violations\n",
    "- Assesses severity and legal implications\n",
    "- Provides specific penalty information\n",
    "- Offers actionable corrective guidance\n",
    "\n",
    "📊 PRODUCTION READY:\n",
    "- Streamlined workflow without reflection overhead\n",
    "- User context enables personalized assessment\n",
    "- Strategic planning improves retrieval relevance\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\\\n🚀 READY FOR PRODUCTION DEPLOYMENT\")\n",
    "print(\"Next: FastAPI backend → Next.js frontend → Docker deployment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
